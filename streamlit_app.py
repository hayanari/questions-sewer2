import os
import json
import requests
import streamlit as st

# ================= ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ =================
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.set_page_config(page_title="ãƒ­ã‚°ã‚¤ãƒ³", page_icon="ğŸ”’", layout="centered")
    st.title("ãƒ­ã‚°ã‚¤ãƒ³")

    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if password == st.secrets["APP_PASSWORD"]:   # secrets.toml ã« APP_PASSWORD ã‚’è¨­å®š
            st.session_state.authenticated = True
            st.success("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸï¼")
            st.experimental_rerun()
        else:
            st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚")

    st.stop()  # ã“ã“ã§å‡¦ç†çµ‚äº† â†’ èªè¨¼ã•ã‚Œã‚‹ã¾ã§ä¸‹ã¯å®Ÿè¡Œã•ã‚Œãªã„

# ================= æœ¬ä½“ã®ã‚¢ãƒ—ãƒªå‡¦ç† =================
st.set_page_config(page_title="ç·åˆæŠ€å£«è©¦é¨“å¯¾ç­–AIã‚¢ãƒ—ãƒªï½œçŸ­ç­”100å­—æ¼”ç¿’", page_icon="ğŸ“", layout="centered")
# ================= åŸºæœ¬è¨­å®š =================
st.set_page_config(page_title="ç·åˆæŠ€å£«è©¦é¨“å¯¾ç­–AIã‚¢ãƒ—ãƒªï½œçŸ­ç­”100å­—æ¼”ç¿’", page_icon="ğŸ“", layout="centered")
os.environ.setdefault("STREAMLIT_SERVER_FILE_WATCHER_TYPE", "none")

API_KEY = st.secrets.get("GEMINI_API_KEY") or st.secrets.get("GOOGLE_API_KEY")
if not API_KEY:
    st.error("âŒ Secrets ã« GEMINI_API_KEYï¼ˆã¾ãŸã¯ GOOGLE_API_KEYï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# å„ªå…ˆé †ä½ï¼ˆä¸Šã»ã©å„ªå…ˆï¼‰
PREFERRED = [
    "gemini-1.5-pro-latest",
    "gemini-1.5-flash-latest",
    "gemini-1.5-pro",
    "gemini-1.5-flash",
    "gemini-1.0-pro",
    "gemini-pro",
]

# ================ å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ================
def _list_models(api_ver: str, timeout=15) -> list[str]:
    """æŒ‡å®š API ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ï¼ˆgenerateContent å¯èƒ½ãªã‚‚ã®ï¼‰"""
    url = f"https://generativelanguage.googleapis.com/{api_ver}/models?key={API_KEY}"
    r = requests.get(url, timeout=timeout)
    r.raise_for_status()
    names = []
    j = r.json()
    for m in j.get("models", []):
        name = (m.get("name") or "").split("/")[-1]  # models/xxx â†’ xxx
        methods = m.get("supportedGenerationMethods") or m.get("supported_generation_methods") or []
        if "generateContent" in methods:
            names.append(name)
    return names

@st.cache_resource(show_spinner=False)
def autodetect_model() -> tuple[str, str] | None:
    """
    v1 â†’ v1beta ã®é †ã§ /models ã‚’å©ã„ã¦ã€ä½¿ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’1ã¤é¸ã¶ã€‚
    return: (api_ver, model) ä¾‹ ("v1", "gemini-1.5-pro-latest")
    ã©ã¡ã‚‰ã‚‚ç©ºãªã‚‰ None
    """
    last_err = None
    for ver in ["v1", "v1beta"]:
        try:
            names = _list_models(ver)
            if not names:
                continue
            # å„ªå…ˆãƒªã‚¹ãƒˆã‹ã‚‰é¸ã¶
            for cand in PREFERRED:
                if cand in names:
                    return ver, cand
            # ç„¡ã‘ã‚Œã°æœ€åˆã®1ä»¶
            return ver, names[0]
        except Exception as e:
            last_err = e
            continue
    return None

def call_gemini(prompt: str, api_ver: str, model: str, timeout=30) -> str:
    url = f"https://generativelanguage.googleapis.com/{api_ver}/models/{model}:generateContent?key={API_KEY}"
    payload = {
        "contents": [{"role": "user", "parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0},
    }
    r = requests.post(url, json=payload, timeout=timeout)
    if r.status_code >= 400:
        raise RuntimeError(f"{api_ver}/{model}: HTTP {r.status_code}: {r.text[:400]}")
    j = r.json()
    return j["candidates"][0]["content"]["parts"][0]["text"]

def parse_json_loose(text: str) -> dict:
    t = (text or "").strip()
    if t.startswith("```"):
        parts = t.split("```")
        if len(parts) >= 3:
            t = parts[1]
    s, e = t.find("{"), t.rfind("}")
    if s == -1 or e == -1 or e <= s:
        raise ValueError("JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    return json.loads(t[s:e+1])

# ================ ãƒ‡ãƒ¼ã‚¿èª­è¾¼ ================
try:
    with open("constants.json", "r", encoding="utf-8") as f:
        QUESTIONS = json.load(f)
except FileNotFoundError:
    st.error("âŒ constants.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()
except json.JSONDecodeError as e:
    st.error(f"âŒ constants.json ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: {e}")
    st.stop()

# ================ ãƒ¢ãƒ‡ãƒ«è‡ªå‹•æ¤œå‡ºï¼ˆUIãªã—ãƒ»èµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘ï¼‰ ================
detected = autodetect_model()
if not detected:
    st.error("âŒ åˆ©ç”¨å¯èƒ½ãª Gemini ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.markdown(
        "- ã¾ãšãƒ–ãƒ©ã‚¦ã‚¶ã§ä¸‹è¨˜URLã‚’é–‹ãã€200ã§ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ãŒè¿”ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚  \n"
        f"`https://generativelanguage.googleapis.com/v1/models?key=ï¼œã‚ãªãŸã®APIã‚­ãƒ¼ï¼`  \n"
        "- 403/404 ã®å ´åˆï¼šAI Studio ã§ **ç”Ÿæˆè¨€èª API ã‚­ãƒ¼** ã‚’æ–°è¦ç™ºè¡Œã—ã€Secrets ã‚’å·®ã—æ›¿ãˆã¦ãã ã•ã„ã€‚  \n"
        "- çµ„ç¹”åˆ¶é™ãŒã‚ã‚‹å ´åˆã¯ Vertex AI ã‚’ã”åˆ©ç”¨ãã ã•ã„ï¼ˆå¿…è¦ãªã‚‰ Vertex ç‰ˆã‚³ãƒ¼ãƒ‰ã‚’ãŠæ¸¡ã—ã—ã¾ã™ï¼‰ã€‚"
    )
    st.stop()

API_VER, MODEL_NAME = detected  # ä¾‹ ("v1", "gemini-1.5-pro-latest")

# ================ ãƒ¡ã‚¤ãƒ³UI ================
st.title("ç·åˆæŠ€å£«è©¦é¨“å¯¾ç­–AIã‚¢ãƒ—ãƒªï½œçŸ­ç­”100å­—æ¼”ç¿’")
st.caption(f"å‡ºå…¸ï¼šä¸‹æ°´é“ç®¡è·¯ç®¡ç†ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ï½œä½¿ç”¨ä¸­: {API_VER} / {MODEL_NAME}")
st.markdown("å‡ºé¡Œã‚’é¸ã‚“ã§å—é¨“è€…ã®è§£ç­”ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€AI ãŒ **10ç‚¹æº€ç‚¹** ã§æ¡ç‚¹ã—ã¾ã™ã€‚")

# ===== å‡ºé¡ŒãƒŠãƒ“ï¼ˆæˆ»ã‚‹ï¼æ¬¡ã¸ ä»˜ãï¼‰ =====
ID_TO_Q = {q["id"]: q for q in QUESTIONS}
ORDERED_IDS = sorted(ID_TO_Q.keys())

# ç¾åœ¨ä½ç½®ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã ã‘ã‚’çŠ¶æ…‹ç®¡ç†
if "q_idx" not in st.session_state:
    st.session_state.q_idx = 0

# selectbox å¤‰æ›´ â†’ q_idx åŒæœŸï¼ˆSession Stateã¸ã®ç›´æ¥ä»£å…¥ã¯ã—ãªã„ï¼‰
def on_select_change():
    sel = st.session_state.get("selected_id", ORDERED_IDS[st.session_state.q_idx])
    st.session_state.q_idx = ORDERED_IDS.index(sel)

def go_prev():
    if st.session_state.q_idx > 0:
        st.session_state.q_idx -= 1

def go_next():
    if st.session_state.q_idx < len(ORDERED_IDS) - 1:
        st.session_state.q_idx += 1

selected_id = st.selectbox(
    "å‡ºé¡Œã‚’é¸ã‚“ã§ãã ã•ã„",
    options=ORDERED_IDS,
    index=st.session_state.q_idx,                   # â† ã“ã‚ŒãŒçœŸã®ã‚½ãƒ¼ã‚¹
    format_func=lambda i: f"{i}: {ID_TO_Q[i].get('subject','No Subject')}",
    key="selected_id",
    on_change=on_select_change,                     # â† å¤‰æ›´æ™‚ã« q_idx ã‚’åŒæœŸ
)

c1, c2, c3 = st.columns([1, 1, 1])
with c1:
    st.button("â† æˆ»ã‚‹", use_container_width=True, on_click=go_prev,
              disabled=(st.session_state.q_idx == 0))
with c2:
    st.markdown(
        f"<div style='text-align:center; font-weight:600;'>"
        f"{st.session_state.q_idx + 1} / {len(ORDERED_IDS)}</div>",
        unsafe_allow_html=True
    )
with c3:
    st.button("æ¬¡ã¸ â†’", use_container_width=True, on_click=go_next,
              disabled=(st.session_state.q_idx == len(ORDERED_IDS) - 1))

current_id = ORDERED_IDS[st.session_state.q_idx]
selected_question = ID_TO_Q[current_id]
problem = selected_question.get("text", "")
reference_default = selected_question.get("modelAnswer", "")

# --- å•é¡Œæ–‡ã¨å…¥åŠ›æ¬„ ---
st.subheader("ğŸ§© å•é¡Œæ–‡")
st.write(problem)

with st.expander("ğŸ“˜ æ¨¡ç¯„è§£ç­”", expanded=False):
    reference = st.text_area("æ¨¡ç¯„è§£ç­”", value=reference_default, height=140, key=f"ref_{current_id}")

student = st.text_area(
    "ğŸ§‘â€ğŸ“ ã‚ãªãŸã®è§£ç­”",
    height=200,
    placeholder="ã“ã“ã«å›ç­”ã‚’å…¥åŠ›â€¦",
    key=f"ans_{current_id}",
)

# æ–‡å­—æ•°ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ï¼ˆ100å­—ç›®å®‰ï¼‰
st.caption(f"ç¾åœ¨ã®æ–‡å­—æ•°: {len(student)} / 100")

strictness = st.slider("æ¡ç‚¹ã®å³ã—ã•ï¼ˆ1=å¯›å®¹, 5=éå¸¸ã«å³æ ¼ï¼‰", 1, 5, 3)
do_eval = st.button("æ¡ç‚¹ã™ã‚‹")

# ================ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ ================
def build_prompt(problem, student, reference, strictness):
    return f"""
ã‚ãªãŸã¯æ—¥æœ¬èªã®å³æ ¼ãªæ¡ç‚¹è€…ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸå•é¡Œæ–‡ã¨å—é¨“è€…ã®è§£ç­”ã‚’è©•ä¾¡ã—ã€JSONã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒï¼ˆä½™è¨ˆãªãƒ†ã‚­ã‚¹ãƒˆã¯ç¦æ­¢ï¼‰:
{{"score": <0-10>,"rubric":"...","strengths":["..."],"weaknesses":["..."],"improvements":["..."],"reasoning":"..."}}
æ¡ç‚¹ã®å³ã—ã•: {strictness}
å•é¡Œæ–‡:
{problem}
å—é¨“è€…ã®è§£ç­”:
{student}
æ¨¡ç¯„è§£ç­”ï¼ˆä»»æ„ã€ç©ºãªã‚‰å‚è€ƒã«ã—ãªã„ï¼‰:
{reference}
"""

# ================ æ¡ç‚¹å‡¦ç† ================
if do_eval:
    if not problem or not student:
        st.warning("âš ï¸ å•é¡Œæ–‡ã¨å—é¨“è€…ã®è§£ç­”ã¯å¿…é ˆã§ã™ã€‚")
        st.stop()

    prompt = build_prompt(problem, student, reference, strictness)

    try:
        with st.spinner("Gemini ãŒæ¡ç‚¹ä¸­â€¦"):
            text = call_gemini(prompt, API_VER, MODEL_NAME, timeout=30)
    except Exception as e:
        st.error("âŒ APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
            st.code(str(e))
            st.markdown(
                "- 403/404 ã®å ´åˆï¼šAI Studio ã® API ã‚­ãƒ¼ç¨®åˆ¥ãƒ»åˆ¶é™ï¼ˆGenerative Language API ã«é™å®š/è¨±å¯ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚  \n"
                "- ãƒ–ãƒ©ã‚¦ã‚¶ã§ `/v1/models?key=...` ã‚’é–‹ãã¨ã€åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ã®æœ‰ç„¡ãŒã™ãç¢ºèªã§ãã¾ã™ã€‚"
            )
        st.stop()

    try:
        data = parse_json_loose(text)
    except Exception:
        st.error("âŒ æ¡ç‚¹çµæœã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿå‡ºåŠ›ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        with st.expander("ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿå‡ºåŠ›"):
            st.code(text or "", language="json")
        st.stop()

    # ======= çµæœè¡¨ç¤ºï¼ˆæ•´å½¢ç‰ˆï¼‰ =======
    st.success(f"âœ… æ¡ç‚¹å®Œäº†ï¼ˆ{API_VER} / {MODEL_NAME}ï¼‰")

    score_val = data.get("score", 0)
    st.markdown(
        f"""
        <div style="font-size:28px;font-weight:700;margin:8px 0 2px 0;">ã‚¹ã‚³ã‚¢</div>
        <div style="font-size:42px;font-weight:800;line-height:1;">{score_val} / 10</div>
        """,
        unsafe_allow_html=True
    )

    st.markdown("### æ¡ç‚¹åŸºæº–ï¼ˆRubricï¼‰")
    st.write(data.get("rubric", ""))

    def norm_list(x):
        if x is None: return []
        if isinstance(x, str): return [x]
        if isinstance(x, (list, tuple)): return [str(i) for i in x if str(i).strip()]
        return [str(x)]

    def render_bullets(items):
        if not items:
            st.markdown("- ï¼ˆè¨˜è¼‰ãªã—ï¼‰")
            return
        st.markdown("\n".join([f"- {i}" for i in items]))

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### ğŸ‘ è‰¯ã‹ã£ãŸç‚¹")
        render_bullets(norm_list(data.get("strengths")))
    with col2:
        st.markdown("### âš ï¸ ä¸è¶³ãƒ»èª¤ã‚Š")
        render_bullets(norm_list(data.get("weaknesses")))

    st.markdown("### ğŸ›  æ”¹å–„ææ¡ˆ")
    render_bullets(norm_list(data.get("improvements")))

    with st.expander("ğŸ§  æ¡ç‚¹ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆç†ç”±ï¼‰", expanded=False):
        st.write(data.get("reasoning", ""))

    # ç®‡æ¡æ›¸ãã®ä½™ç™½èª¿æ•´
    st.markdown(
        """
        <style>
        ul { margin-top: 0.25rem; margin-bottom: 0.75rem; }
        li { margin: 0.25rem 0; }
        </style>
        """,
        unsafe_allow_html=True
    )

st.markdown("---")
st.caption("Powered by Streamlit Ã— Google Geminiï¼ˆREST / è‡ªå‹•ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºï¼‰ ãƒ» å•é¡Œãƒ‡ãƒ¼ã‚¿: constants.json")
